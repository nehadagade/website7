---
title: "Climate change and temperature anomalies"
date: "`r Sys.Date()`"
description: " "
draft: no
image: climate change.jpeg
keywords: ''
slug: climate
categories:
- ''
- ''
---

```{r, setup, include=FALSE}
knitr::opts_chunk$set(
  message = FALSE, 
  warning = FALSE, 
  tidy=FALSE,     # display code as typed
  size="small")   # slightly smaller font for code
options(digits = 3)

# default figure size
knitr::opts_chunk$set(
  fig.width=6.75, 
  fig.height=6.75,
  fig.align = "center"
)
```

```{r load-libraries, include=FALSE}
library(tidyverse)  # Load ggplot2, dplyr, and all the other tidyverse packages
library(mosaic)
library(ggthemes)
library(lubridate)
library(here)
library(skimr)
library(janitor)
library(httr)
library(readxl)
library(vroom)
library(wbstats)
library(countrycode)
library(patchwork)
library(gganimate)
library(infer)
library(scales)
```

# Climate change and temperature anomalies


```{r weather_data, cache=TRUE}

weather <- 
  read_csv("https://data.giss.nasa.gov/gistemp/tabledata_v4/NH.Ts+dSST.csv", 
           skip = 1, 
           na = "***")

```

For each month and year, the dataframe shows the deviation of
temperature from the normal (expected). Further the dataframe is in wide
format.

**Cleaning Data**

```{r tidyweather}

tidyweather <- weather %>% 
  select(1:13) %>% 
  pivot_longer( cols = 2:13,
                names_to = "Month",
                values_to = "delta")

glimpse(tidyweather)

```

## Plotting Information

Plotting data using a time-series scatterplot with a trendline.

```{r scatter_plot}

tidyweather <- tidyweather %>%
  mutate(date = ymd(paste(as.character(Year), Month, "1")),
         month = month(date, label=TRUE),
         year = year(date))

ggplot(tidyweather, aes(x=date, y = delta))+
  geom_point()+
  geom_smooth(color="red") +
  theme_bw() +
  labs (
    title = "Weather Anomalies",
    x = "Year",
    y = "Temperature deviaton",
    caption = "Source: https://data.giss.nasa.gov/gistemp/tabledata_v4/NH.Ts+dSST.txt"
  ) +
  NULL

```


Producing a scatter plot showing the temperature anomalies by month.


```{r facet_wrap}

ggplot(tidyweather, aes(x=date, y = delta))+
  geom_point()+
  geom_smooth(color="red") +
  theme_bw() +
  labs (
    title = "Weather Anomalies",
    x = "Year",
    y = "Temperature deviaton",
    caption = "Source: https://data.giss.nasa.gov/gistemp/tabledata_v4/NH.Ts+dSST.txt"
  ) +
  facet_wrap(~month) +
  NULL

```

Grouping data into different time periods to study historical data.

```{r intervals}

comparison <- tidyweather %>% 
  filter(Year>= 1881) %>%     #remove years prior to 1881
  #create new variable 'interval', and assign values based on criteria below:
  mutate(interval = case_when(
    Year %in% c(1881:1920) ~ "1881-1920",
    Year %in% c(1921:1950) ~ "1921-1950",
    Year %in% c(1951:1980) ~ "1951-1980",
    Year %in% c(1981:2010) ~ "1981-2010",
    TRUE ~ "2011-present"
  ))

comparison

```

Creating a density plot to study the distribution of monthly deviations
grouped by the different time periods.

```{r density_plot}

ggplot(data = comparison, aes(delta)) +
  geom_density(aes(fill = interval), alpha = 1/4) +
  labs(title = "Distribution of Monthly Temperature Anomalies in Time Intervals",
       x = "Monthly Temperature Anomaly", 
       y = "Density",
    caption = "Source: https://data.giss.nasa.gov/gistemp/tabledata_v4/NH.Ts+dSST.txt") +
  facet_wrap(~ interval, ncol = 1) +
  theme_bw() +
  theme(legend.position = "none") +
  NULL

```

Calculating average annual anomalies.

```{r averaging}

#creating yearly averages
average_annual_anomaly <- tidyweather %>% 
  group_by(Year) %>%   #grouping data by Year
  
  # creating summaries for mean delta 
  summarise(mean_delta = mean(delta, na.rm=TRUE))

#plotting the data:

ggplot(average_annual_anomaly, 
       aes (x = Year,
            y = mean_delta)) +
  geom_point() +
  theme_bw() +
  geom_smooth(method = "loess") +
  labs(title = "Average annual anomalies by year",
       y = "Average annual anomalies",
    caption = "Source: https://data.giss.nasa.gov/gistemp/tabledata_v4/NH.Ts+dSST.txt") +
  NULL

```

## Confidence Interval for `delta`

[NASA points out on their
website](https://earthobservatory.nasa.gov/world-of-change/decadaltemp.php)
that

> A one-degree global change is significant because it takes a vast
> amount of heat to warm all the oceans, atmosphere, and land by that
> much. In the past, a one- to two-degree drop was all it took to plunge
> the Earth into the Little Ice Age.

Construction of a confidence interval for the average annual delta since
2011, both using a formula and using a bootstrap simulation with the
`infer` package.

```{r, calculate_CI_using_formula}

formula_ci <- comparison %>% 
  filter(interval == "2011-present") %>% # choose the interval 2011-present
  filter(!delta == "NA") %>% # drop NA observations in delta
  summarise(count = n(),
            t = qt(0.975, count-1), # use qt with probability and degrees of freedom
            mean = mean(delta), # calculate mean
            sd = sd(delta), # calculate sd
            se = sd(delta)/sqrt(count), # calculate se
            margin = t * se, # calculate margin of error
            lower = mean - margin, # calculate lower bound
            upper = mean + margin #calculate upper bound
            
  )

#print out formula_CI
formula_ci
```

```{r, calculate_CI_bootstrap}
library(infer)

set.seed(1234)

boot_ci <- comparison %>% 
  filter(interval == "2011-present") %>% # choose the interval 2011-present
  filter(!delta == "NA") %>% # drop NA observations in delta
  specify(response = delta) %>% # specify the variable of interest
  generate(reps = 1000, type = "bootstrap") %>% # extract 1000 bootstrap samples
  calculate(stat = "mean") %>% # calculate sample means from each bootstrap sample
  get_confidence_interval(level = 0.95, type = "percentile") # calculate confidence interval of this analysis

# Display confidence interval
boot_ci
```

> Two different methods of constructing 95% confidence interval were
> used in this example. First was based on filtering appropriate
> interval and calculating confidence interval using summary statistics.
> Second involved 'infer' package, which allowed to use bootstrap method
> and produced the confidence intervals without any additional summary
> statistics. According to the summary calculations the average annual
> anomalies since 2011 already exceeded 1 degree, even when 95%
> confidence interval is taken into account. Therefore, it is highly
> likely that anomalies will become even more frequent and significant
> than before.

